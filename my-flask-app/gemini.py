# -*- coding: utf-8 -*-

# my-flask-app/gemini.py
import google.generativeai as genai
import os
import asyncio
import hashlib
import aiohttp
from datetime import datetime, timedelta
from typing import List, Dict
from functools import lru_cache
from config import GOOGLE_API_KEY, DISCORD_WEBHOOK_URL, DOCUMENT_TYPES
import requests

# Gemini ì„¤ì •
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# ìºì‹œ ë° rate limit ì„¤ì •
_analysis_cache = {}
_rate_limit = asyncio.Semaphore(10)  # ë™ì‹œ ìš”ì²­ ì œí•œ
_last_request_time = {}
MIN_REQUEST_INTERVAL = 0.1  # ì´ˆë‹¹ ìµœëŒ€ 10ê°œ ìš”ì²­

class DocumentAnalyzer:
    def __init__(self):
        self._session = None
        self._cache = {}
        
    async def get_session(self):
        """ë¹„ë™ê¸° HTTP ì„¸ì…˜ ê´€ë¦¬"""
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
        return self._session

    @lru_cache(maxsize=1000)
    def calculate_risk_score(self, missing_docs: tuple) -> int:
        """ë¬¸ì„œ ëˆ„ë½ì— ë”°ë¥¸ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (ì˜¤í”„ë¼ì¸)"""
        base_score = 100
        risk_weights = {
            'contract': 30,    # ê³„ì•½ì„œ
            'specification': 25,  # ê³¼ì—…ì§€ì‹œì„œ
            'budget': 20,      # ì‹¤í–‰ì˜ˆì‚°
            'completion': 15,   # ì¤€ê³µê³„
            'evaluation': 10    # ìš©ì—­ìˆ˜í–‰í‰ê°€
        }
        
        for doc in missing_docs:
            if doc in risk_weights:
                base_score -= risk_weights[doc]
        
        return max(0, base_score)

    def _generate_cache_key(self, project_data: dict) -> str:
        """ìºì‹œ í‚¤ ìƒì„± (ë¬¸ì„œ ìƒíƒœ í•´ì‹œ í¬í•¨)"""
        docs_hash = hashlib.md5(str(project_data['documents']).encode()).hexdigest()
        return f"{project_data['project_id']}_{datetime.now().strftime('%Y%m%d')}_{docs_hash}"

    async def _wait_for_rate_limit(self):
        """Rate limit ì¤€ìˆ˜"""
        async with _rate_limit:
            now = datetime.now()
            if self._last_request_time.get(os.getpid()):
                elapsed = (now - self._last_request_time[os.getpid()]).total_seconds()
                if elapsed < MIN_REQUEST_INTERVAL:
                    await asyncio.sleep(MIN_REQUEST_INTERVAL - elapsed)
            self._last_request_time[os.getpid()] = now

    async def analyze_batch(self, projects: List[Dict]) -> List[Dict]:
        """í”„ë¡œì íŠ¸ ë°°ì¹˜ ë¶„ì„"""
        tasks = [self.analyze_with_gemini(project) for project in projects]
        return await asyncio.gather(*tasks)

    async def analyze_with_gemini(self, project_data: Dict) -> str:
        """ê°œë³„ í”„ë¡œì íŠ¸ ë¶„ì„"""
        try:
            cache_key = self._generate_cache_key(project_data)
            if cache_key in self._cache:
                return self._cache[cache_key]

            # ë¬¸ì„œ ìƒíƒœ ë¶„ì„
            missing_docs = []
            existing_docs = []
            for doc_type, info in project_data['documents'].items():
                doc_name = DOCUMENT_TYPES[doc_type]['name']
                if info['exists']:
                    files_count = len(info['details'])
                    existing_docs.append(f"{doc_name} ({files_count}ê°œ)")
                else:
                    missing_docs.append(doc_type)

            # ì˜¤í”„ë¼ì¸ ìœ„í—˜ë„ ê³„ì‚°
            risk_score = self.calculate_risk_score(tuple(missing_docs))

            # ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸
            prompt = f"""
í”„ë¡œì íŠ¸ {project_data['project_id']} ë¬¸ì„œ ë¶„ì„:
ë¶€ì„œ: {project_data['department']}

í˜„í™©:
- í™•ì¸ëœ ë¬¸ì„œ: {', '.join(existing_docs)}
- ëˆ„ë½ëœ ë¬¸ì„œ: {', '.join([DOCUMENT_TYPES[d]['name'] for d in missing_docs])}
- ê¸°ë³¸ ìœ„í—˜ë„: {risk_score}/100

ë‹¤ìŒ ì‚¬í•­ì„ ê°„ë‹¨íˆ í‰ê°€í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ë¬¸ì„œí™” ìƒíƒœ (ìƒ/ì¤‘/í•˜)
2. ê°€ì¥ ì‹œê¸‰í•œ ë³´ì™„ í•„ìš” ë¬¸ì„œ
3. ìœ„í—˜ë„ ì ìˆ˜ ì¡°ì • í•„ìš”ì„± (ìˆë‹¤ë©´)

ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
            # Rate limit ê´€ë¦¬
            await self._wait_for_rate_limit()

            # Gemini API í˜¸ì¶œ
            response = await asyncio.to_thread(model.generate_content, prompt)
            
            analysis = f"""ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ({datetime.now().strftime('%Y-%m-%d %H:%M')}):
{response.text}

ìš”ì•½:
- í™•ì¸ëœ ë¬¸ì„œ: {len(existing_docs)}ê°œ ìœ í˜•
- ëˆ„ë½ëœ ë¬¸ì„œ: {len(missing_docs)}ê°œ ìœ í˜•
- ê¸°ë³¸ ìœ„í—˜ë„: {risk_score}/100
"""
            # ìºì‹œ ì €ì¥
            self._cache[cache_key] = analysis

            # Discord ì•Œë¦¼ (ì„ íƒì )
            if DISCORD_WEBHOOK_URL:
                session = await self.get_session()
                notification = f"ğŸ” í”„ë¡œì íŠ¸ {project_data['project_id']} ë¶„ì„ ì™„ë£Œ (ìœ„í—˜ë„: {risk_score})"
                async with session.post(DISCORD_WEBHOOK_URL, json={'content': notification}) as resp:
                    await resp.read()

            return analysis

        except Exception as e:
            error_msg = f"AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            if DISCORD_WEBHOOK_URL:
                session = await self.get_session()
                async with session.post(DISCORD_WEBHOOK_URL, json={'content': f"âŒ {error_msg}"}) as resp:
                    await resp.read()
            return error_msg

    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self._cache.clear()
        self.calculate_risk_score.cache_clear()

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self._session and not self._session.closed:
            await self._session.close()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
analyzer = DocumentAnalyzer()

async def analyze_with_gemini(project_data: Dict) -> str:
    """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ë¥¼ ìœ„í•œ ë˜í¼"""
    return await analyzer.analyze_with_gemini(project_data)

def clear_analysis_cache():
    """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ë¥¼ ìœ„í•œ ë˜í¼"""
    analyzer.clear_cache()

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    async def test():
        test_data = {
            'project_id': '20230001',
            'department': 'ë„ë¡œì„¤ê³„ë¶€',
            'documents': {
                'contract': {'exists': True, 'details': [{'name': 'contract1.pdf'}, {'name': 'contract2.pdf'}]},
                'specification': {'exists': False, 'details': []},
                'budget': {'exists': True, 'details': [{'name': 'budget.xlsx'}]}
            }
        }
        
        try:
            result = await analyze_with_gemini(test_data)
            print(result)
        finally:
            await analyzer.close()

    asyncio.run(test())

# python gemini.py
 