# /my_flask_app/audit_service.py

import os
import asyncio
import aiofiles
from datetime import datetime
import json
import aiohttp
import re
from pathlib import Path
from search_project_data import ProjectDocumentSearcher
from gemini import analyze_with_gemini
from config import PROJECT_LIST_CSV, NETWORK_BASE_PATH, DISCORD_WEBHOOK_URL, STATIC_DATA_PATH,STATIC_PATH, CONTRACT_STATUS_CSV
from config_assets import DOCUMENT_TYPES, DEPARTMENT_MAPPING, DEPARTMENT_NAMES, AUDIT_FILTERS  # AUDIT_FILTERS ì¶”ê°€
import logging
import pandas as pd
import orjson
import time
from get_project import get_project_info  # get_project.pyì—ì„œ í•¨ìˆ˜ ì„í¬íŠ¸
import ast
from audit_message import send_audit_to_discord, send_audit_status_to_discord  # âœ… ì¶”ê°€
import csv
from functools import lru_cache

# JSON íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
RESULTS_DIR = os.path.join(STATIC_PATH, 'results')  # âœ… `static/data/results` í´ë”ì— ì €ì¥
os.makedirs(RESULTS_DIR, exist_ok=True)

logger = logging.getLogger(__name__)

class AuditService:
    def __init__(self):
        self.searcher = ProjectDocumentSearcher(verbose=False)
        self._session = None
        self.csv_path = os.path.join(STATIC_DATA_PATH, 'combined_report_20250305.csv')

    @lru_cache(maxsize=128)
    async def load_csv_data(self):
        """CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ìºì‹œ"""
        projects = []
        try:
            with open(self.csv_path, newline='', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    projects.append(row)
            return projects
        except Exception as e:
            logger.error(f"Error loading CSV: {e}")
            return []

    def convert_project_to_json(self, project):
        """í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        documents = {
            'contract': {'exists': bool(int(project['contract_exists'])), 'details': []},
            'specification': {'exists': bool(int(project['specification_exists'])), 'details': []},
            'initiation': {'exists': bool(int(project['initiation_exists'])), 'details': []},
            'agreement': {'exists': bool(int(project['agreement_exists'])), 'details': []},
            'budget': {'exists': bool(int(project['budget_exists'])), 'details': []},
            'deliverable1': {'exists': bool(int(project['deliverable1_exists'])), 'details': []},
            'deliverable2': {'exists': bool(int(project['deliverable2_exists'])), 'details': []},
            'completion': {'exists': bool(int(project['completion_exists'])), 'details': []},
            'certificate': {'exists': bool(int(project['certificate_exists'])), 'details': []},
            'evaluation': {'exists': bool(int(project['evaluation_exists'])), 'details': []}
        }
        
        return {
            'project_id': project['project_id'],
            'project_name': project['project_name'],
            'department': project['department'],
            'status': project['Status'],
            'contractor': project['Contractor'],
            'documents': documents,
            'timestamp': project.get('timestamp', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        }

    async def _get_session(self):
        """aiohttp ì„¸ì…˜ ê´€ë¦¬"""
        if self._session is None:
            self._session = aiohttp.ClientSession()
        return self._session

    async def close(self):
        """ì„¸ì…˜ ì •ë¦¬"""
        if self._session is not None:
            await self._session.close()
            self._session = None

    async def save_audit_result(self, result, department_code):
        """ê°ì‚¬ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•˜ë©°, ì˜ëª»ëœ ë¬¸ìì—´ì„ ë³€í™˜"""
        project_id = result['project_id']
        
        # ê¸°ì¡´: audit_20240178_06010.json í˜•ì‹
        # filename = f"audit_{project_id}_{department_code}.json"
        
        # ë³€ê²½: audit_20240178.json í˜•ì‹
        filename = f"audit_{project_id}.json"
        
        filepath = os.path.join(RESULTS_DIR, filename)
        
        if not os.path.exists(RESULTS_DIR):
            os.makedirs(RESULTS_DIR, exist_ok=True)
        
        # JSON ë‚´ ë¬¸ìì—´ í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ë³€í™˜
        def fix_document_details(details):
            if isinstance(details, list):
                corrected_details = []
                for item in details:
                    if isinstance(item, str):
                        try:
                            item = json.loads(item.replace("'", "\""))  # ë¬¸ìì—´ì„ JSONìœ¼ë¡œ ë³€í™˜
                        except json.JSONDecodeError:
                            pass  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë˜ ê°’ ìœ ì§€
                    corrected_details.append(item)
                return corrected_details
            return details

        # ëª¨ë“  ë¬¸ì„œ í•­ëª©ì—ì„œ ë¬¸ìì—´ë¡œ ì €ì¥ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ ë³€í™˜
        for doc_type, doc_info in result.get('documents', {}).items():
            if 'details' in doc_info:
                doc_info['details'] = fix_document_details(doc_info['details'])

        # JSON ì €ì¥
        async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(result, ensure_ascii=False, indent=2))

        logger.info(f"âœ… ê°ì‚¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath


    async def _send_single_to_discord(self, data, ctx=None):
        """ë‹¨ì¼ ê°ì‚¬ ê²°ê³¼ë¥¼ Discordë¡œ ì „ì†¡ (ë‚´ë¶€ í•¨ìˆ˜)"""
        if not isinstance(data, dict):
            logger.error(f"Invalid audit data format: {data}")
            return False

        # Unknown í”„ë¡œì íŠ¸ ê²°ê³¼ëŠ” ì „ì†¡í•˜ì§€ ì•ŠìŒ
        if data.get('project_id') == 'Unknown' and data.get('department') == 'Unknown':
            logger.warning("Skipping Unknown project result")
            return True

            message = (
                f"ğŸ“‹ **Project Audit Result**\n"
            f"ID: {data.get('project_id', 'Unknown')}\n"
            f"Department: {data.get('department', data.get('department_code', 'Unknown'))}\n"
            f"Name: {data.get('project_name', f'Project {data.get('project_id', 'Unknown')}')}\n"
            f"Status: {data.get('status', 'Unknown')}\n"  # Status ì¶”ê°€
            f"Contractor: {data.get('contractor', 'Unknown')}\n"  # Contractor ì¶”ê°€
            f"Path: {data.get('project_path', 'Unknown')}\n\n"  # 'original_folder' ëŒ€ì‹  'project_path' ì‚¬ìš©
                f"ğŸ“‘ Documents:\n"
            )

            found_docs = []
            missing_docs = []
        documents = data.get('documents', {})
        
        # ëª¨ë“  DOCUMENT_TYPESë¥¼ ìˆœíšŒí•˜ë©° ì²˜ë¦¬
        for doc_type in DOCUMENT_TYPES.keys():
            doc_info = documents.get(doc_type, {'exists': False, 'details': []})
            doc_name = DOCUMENT_TYPES.get(doc_type, {}).get('name', doc_type)
            if doc_info.get('exists', False):  # existsê°€ Trueì¸ ê²½ìš°
                count = len(doc_info.get('details', []))
                found_docs.append(f"{doc_name} ({count}ê°œ)")
                else:
                missing_docs.append(f"{doc_name} (0ê°œ)")  # ë°œê²¬ë˜ì§€ ì•Šì€ ë¬¸ì„œëŠ” 0ê°œë¡œ í‘œì‹œ

            if found_docs:
                message += "âœ… Found:\n- " + "\n- ".join(found_docs) + "\n\n"
            if missing_docs:
            message += "âŒ Missing:\n- " + "\n- ".join(missing_docs) + "\n\n"

        if 'ai_analysis' in data and data['ai_analysis']:
            message += f"\nğŸ¤– AI Analysis:\n{data['ai_analysis']}"

        message += f"\nâ° {data.get('timestamp', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))}"

        try:
            if ctx:
                # ctxê°€ ìˆëŠ” ê²½ìš° ë””ìŠ¤ì½”ë“œ ì±„ë„ì— ì§ì ‘ ë©”ì‹œì§€ ì „ì†¡
            await ctx.send(message)
                logger.info(f"Sent audit result to Discord channel: {message}")
        elif DISCORD_WEBHOOK_URL:
                # ctxê°€ ì—†ìœ¼ë©´ ì›¹í›…ìœ¼ë¡œ ì „ì†¡
            async with aiohttp.ClientSession() as session:
                try:
                    async with session.post(DISCORD_WEBHOOK_URL, json={'content': message}, timeout=10) as response:
                        if response.status != 204:
                            logger.warning(f"Webhook response status: {response.status}")
                                print(f"Failed to send to Discord webhook: {message}")
                                return False
                        logger.info("Audit result successfully sent to Discord webhook")
                        return True
                    except asyncio.TimeoutError:
                        logger.error("Timeout while sending to Discord webhook")
                        print(f"Timeout while sending to Discord webhook: {message}")
                        return False
                    except Exception as e:
                        logger.error(f"Error sending to Discord webhook: {str(e)}")
                        print(f"Failed to send to Discord webhook: {message}")
                        return False
            else:
                            print(message)
                return True
                except Exception as e:
            logger.error(f"Error sending to Discord: {str(e)}")
            if ctx:
                await ctx.send(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
        else:
                print(f"Failed to send to Discord: {message}")
            return False

    def load_contract_data(self):
        """contract_status.csvì—ì„œ í”„ë¡œì íŠ¸ ì •ë³´ë¥¼ ë¡œë“œ"""
        try:
            df = pd.read_csv(CONTRACT_STATUS_CSV, encoding='utf-8-sig')
            if 'ì‚¬ì—…ì½”ë“œ' not in df.columns or 'PMë¶€ì„œ' not in df.columns or 'ì§„í–‰ìƒíƒœ' not in df.columns or 'ì‚¬ì—…ëª…' not in df.columns or 'ì£¼ê´€ì‚¬' not in df.columns:
                raise ValueError("CSV must contain 'ì‚¬ì—…ì½”ë“œ', 'PMë¶€ì„œ', 'ì§„í–‰ìƒíƒœ', 'ì‚¬ì—…ëª…', and 'ì£¼ê´€ì‚¬' columns")

            # PMë¶€ì„œì—ì„œ ë¶€ì„œ ì½”ë“œë¡œ ë§¤í•‘
            def map_department(pm_dept):
                dept_name = pm_dept.strip()
                dept_code = DEPARTMENT_MAPPING.get(dept_name, '99999')
                return dept_code

            # ProjectID ìƒì„± (ì‚¬ì—…ì½”ë“œì—ì„œ ì•ŒíŒŒë²³ ì œê±°)
            df['ProjectID'] = df['ì‚¬ì—…ì½”ë“œ'].apply(lambda x: re.sub(r'[^0-9]', '', str(x)))
            
            # ë¶€ì„œ ì½”ë“œ ë§¤í•‘
            df['Depart_Code'] = df['PMë¶€ì„œ'].apply(map_department)
            df['Depart'] = df['Depart_Code'].map(DEPARTMENT_NAMES).fillna(df['PMë¶€ì„œ'])
            
            # Contractor ë§¤í•‘
            df['Contractor'] = df['ì£¼ê´€ì‚¬'].apply(lambda x: 'ì£¼ê´€ì‚¬' if x == 'ì£¼ê´€ì‚¬' else 'ë¹„ì£¼ê´€ì‚¬')
            
            return df[['ProjectID', 'Depart_Code', 'Depart', 'ì§„í–‰ìƒíƒœ', 'ì‚¬ì—…ëª…', 'Contractor']]
        except Exception as e:
            logger.error(f"Failed to load contract data from {CONTRACT_STATUS_CSV}: {str(e)}")
            return pd.DataFrame()

    async def search_projects_by_id(self, project_id, department_code=None):
        """project_idë§Œ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œì íŠ¸ ì •ë³´ ë° í´ë”ë¥¼ ì°¾ì•„ ê²€ìƒ‰ (ë¶€ì„œ ì½”ë“œë¥¼ í•„ìˆ˜ë¡œ ìš”êµ¬í•˜ì§€ ì•ŠìŒ)"""
        numeric_project_id = re.sub(r'[^0-9]', '', str(project_id))
        projects = []
        
        # 1) contract_status.csvì—ì„œ í”„ë¡œì íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë¶€ì„œ ì½”ë“œ ì—†ì´ ê²€ìƒ‰)
        contract_df = self.load_contract_data()
        contract_match = contract_df[contract_df['ProjectID'] == numeric_project_id]
        
        if not contract_match.empty:
            row = contract_match.iloc[0]
            dept_code = row['Depart_Code']
            dept_name = row['Depart']
            project_name = row['ì‚¬ì—…ëª…']
            status = row['ì§„í–‰ìƒíƒœ']
            contractor = row['Contractor']
        else:
            # contract_status.csvì— ì—†ìœ¼ë©´ get_project_infoë¡œ ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë¶€ì„œ ì½”ë“œ ì—†ì´)
            loop = asyncio.get_event_loop()
            project_info = await loop.run_in_executor(None, lambda: get_project_info(project_id))
            if not project_info:
                logger.warning(f"Project ID {numeric_project_id} not found in contract status, using default values")
                dept_code = '99999'  # ê¸°ë³¸ ë¶€ì„œ ì½”ë“œ
                dept_name = 'Unknown'
                project_name = f'Project {numeric_project_id}'
                status = 'Unknown'
                contractor = 'Unknown'
            else:
                dept_code = project_info['department_code']
                dept_name = project_info['department_name']
                project_name = project_info['project_name']
                status = project_info.get('status', 'Unknown')
                contractor = project_info.get('contractor', 'Unknown')

        # ë¶€ì„œ ì½”ë“œê°€ ì—†ìœ¼ë©´ contract_status.csv ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
        if not department_code:
            department_code = dept_code

        # audit_targets_new.csvì—ì„œ search_folder í™•ì¸ (ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ê²€ìƒ‰)
        csv_path = os.path.join(STATIC_DATA_PATH, 'audit_targets_new.csv')
        search_folder = None
        try:
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            project_row = df[df['ProjectID'] == str(project_id)]
            if not project_row.empty:
                search_folder = str(project_row['search_folder'].iloc[0])
                if search_folder in ["No folder", "No directory"]:
                    logger.warning(f"Project {project_id} has No folder/No directory in audit_targets_new.csv, searching default path")
                    search_folder = None  # ê¸°ë³¸ ê²½ë¡œë¡œ ê²€ìƒ‰
            else:
                logger.warning(f"Project {project_id} not found in audit_targets_new.csv, searching default path")
        except Exception as e:
            logger.error(f"Error reading audit_targets_new.csv: {str(e)}")

        # project_list.csvì—ì„œ original_folder í™•ì¸ (ê²½ë¡œ ê²€ìƒ‰)
        project_list_path = PROJECT_LIST_CSV
        if os.path.exists(project_list_path):
            try:
                df_projects = pd.read_csv(project_list_path, encoding='utf-8-sig')
                df_projects['project_id'] = df_projects['project_id'].apply(lambda x: re.sub(r'[^0-9]', '', str(x)))
                project_row_pl = df_projects[df_projects['project_id'] == numeric_project_id]
                if not project_row_pl.empty:
                    original_folder = project_row_pl['original_folder'].iloc[0]
                    folder_path = os.path.join(NETWORK_BASE_PATH, original_folder)
                    if os.path.exists(folder_path):
                        search_folder = folder_path
                        logger.info(f"Found project folder for Project {project_id}: {search_folder}")
                    else:
                        logger.warning(f"Project folder not found: {folder_path}")
                else:
                    logger.warning(f"No project found in project_list.csv for numeric ID {numeric_project_id} (original: {project_id})")
            except Exception as e:
                logger.error(f"Error reading project_list.csv: {str(e)}")

        # ê¸°ë³¸ ê²½ë¡œ ê²€ìƒ‰ (NETWORK_BASE_PATH ì•„ë˜)
        if not search_folder or search_folder in ["No folder", "No directory"]:
            base_paths = [
                os.path.join(NETWORK_BASE_PATH, numeric_project_id),  # ê¸°ë³¸ project_id
                os.path.join(NETWORK_BASE_PATH, f"Y{numeric_project_id}"),  # Y ì ‘ë‘ì‚¬ í¬í•¨
                os.path.join(NETWORK_BASE_PATH, f"{numeric_project_id}_")  # project_id_ ì ‘ë¯¸ì‚¬
            ]
            for path in base_paths:
                if os.path.exists(path):
                    search_folder = path
                    logger.info(f"Found default folder path for Project {project_id}: {search_folder}")
                    break
            if not search_folder:
                logger.warning(f"No default folder path found for Project {project_id} after search on {NETWORK_BASE_PATH}")
                return [{
                    'project_id': numeric_project_id,
                    'department_code': dept_code,
                    'department_name': dept_name,
                    'project_name': project_name,
                    'original_folder': None,
                    'status': status,
                    'contractor': contractor,
                    'documents': {doc_type: {'exists': False, 'details': []} for doc_type in DOCUMENT_TYPES}
                }]

        # ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (search_folderê°€ No folder/No directoryê°€ ì•„ë‹Œ ê²½ìš°)
        if search_folder not in ["No folder", "No directory"]:
            if not await asyncio.to_thread(os.path.exists, search_folder):
                logger.error(f"Project folder does not exist: {search_folder}")
                return [{
                    'project_id': numeric_project_id,
                    'department_code': dept_code,
                    'department_name': dept_name,
                    'project_name': project_name,
                    'original_folder': search_folder,
                    'status': status,
                    'contractor': contractor,
                    'documents': {doc_type: {'exists': False, 'details': []} for doc_type in DOCUMENT_TYPES}
                }]

            # 2) search_project_data.pyì˜ process_single_project í˜¸ì¶œ (project_idë§Œ ì „ë‹¬)
            search_result = await self.searcher.process_single_project(project_id)  # department_code ì œê±°
            if search_result:
                logger.debug(f"Raw search result for project {numeric_project_id}: {search_result}")
                
                documents = search_result.get('documents', {})
                processed_documents = {}
                
                # ëª¨ë“  DOCUMENT_TYPESë¥¼ ìˆœíšŒí•˜ë©° ì²˜ë¦¬
                for doc_type, type_info in DOCUMENT_TYPES.items():
                    doc_data = documents.get(doc_type, [])
                    
                    if isinstance(doc_data, list):
                        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (íŒŒì¼ ê²½ë¡œ ëª©ë¡)
                        details = [{'name': str(path), 'path': str(path)} for path in doc_data if path]
                        processed_documents[doc_type] = {
                            'exists': bool(details),
                            'details': details
                        }
                        logger.debug(f"Processed list {doc_type}: {len(details)} files")
                    elif isinstance(doc_data, dict):
                        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                        details = doc_data.get('details', [])
                        if isinstance(details, list):
                            processed_details = [
                                {'name': str(item), 'path': str(item)} if isinstance(item, (str, Path))
                                else item if isinstance(item, dict) and 'name' in item
                                else {'name': str(item), 'path': str(item)}
                                for item in details if item
                            ]
                            processed_documents[doc_type] = {
                                'exists': bool(processed_details),
                                'details': processed_details
                            }
                            logger.debug(f"Processed dict {doc_type}: {len(processed_details)} files")
                    else:
                        # ê¸°íƒ€ ê²½ìš° ë¹ˆ ê²°ê³¼ë¡œ ì²˜ë¦¬
                        processed_documents[doc_type] = {
                            'exists': False,
                            'details': []
                        }
                        logger.debug(f"Empty result for {doc_type}")

                total_files = sum(len(doc_info['details']) for doc_info in processed_documents.values())
                logger.info(f"Total processed files: {total_files}")

                if total_files > 0 or processed_documents:
                    projects.append({
                        'project_id': numeric_project_id,
                        'department_code': dept_code,
                        'department_name': dept_name,
                        'project_name': project_name,
                        'original_folder': search_folder,
                        'status': status,
                        'contractor': contractor,
                        'documents': processed_documents
                    })
                    logger.info(f"Found project path for {numeric_project_id}: {search_folder}")
                    logger.info(f"Project metadata - Status: {status}, Contractor: {contractor}")
                    logger.info(f"Total files found: {total_files}")
        
        return projects

    async def audit_project(self, project_id, department_code=None, use_ai=False, ctx=None):
        """ë‹¨ì¼ í”„ë¡œì íŠ¸ ê°ì‚¬ (CSV ê¸°ë°˜)"""
        try:
            # CSV ë°ì´í„°ì—ì„œ í”„ë¡œì íŠ¸ ê²€ìƒ‰
            projects = await self.load_csv_data()
            for project in projects:
                if project['project_id'] == project_id:
                    result = self.convert_project_to_json(project)
                    
                    # AI ë¶„ì„ ì¶”ê°€ (use_aiê°€ Trueì¸ ê²½ìš°)
            if use_ai:
                        try:
                ai_input = {
                    'project_id': project_id,
                                'department': result['department'],
                                'project_name': result['project_name'],
                                'status': result['status'],
                                'contractor': result['contractor'],
                                'documents': result['documents'],
                                'csv_data': project
                            }
                            result['ai_analysis'] = await analyze_with_gemini(ai_input, await self._get_session())
                        except Exception as e:
                            logger.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                            result['ai_analysis'] = f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                    
                    # Discordë¡œ ê²°ê³¼ ì „ì†¡
                    try:
                        await send_audit_to_discord(result)
                    except Exception as e:
                        logger.error(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
                    
                    return [result]  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì—¬ ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
            
            raise Exception(f'Project ID {project_id} not found')
            
        except Exception as e:
            error_msg = f"í”„ë¡œì íŠ¸ {project_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logger.error(error_msg)
            if ctx:
                await ctx.send(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
            return [{
                'error': str(e),
                'project_id': project_id,
                'department_code': department_code,
                'department': 'Unknown',
                'status': 'Unknown',
                'contractor': 'Unknown',
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }]

    async def audit_multiple_projects(self, project_ids=None, department_codes=None, use_ai=False):
        """ë‹¤ì¤‘ í”„ë¡œì íŠ¸ ê°ì‚¬ (CSV ê¸°ë°˜)"""
        try:
            projects = await self.load_csv_data()
            results = []
            
            # project_idsê°€ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ í”„ë¡œì íŠ¸ë§Œ ì²˜ë¦¬
            if project_ids:
                target_projects = [p for p in projects if p['project_id'] in project_ids]
            else:
                target_projects = projects
            
            for project in target_projects:
                result = self.convert_project_to_json(project)
                
                if use_ai:
                    try:
                        ai_input = {
                            'project_id': project['project_id'],
                            'department': result['department'],
                            'project_name': result['project_name'],
                            'status': result['status'],
                            'contractor': result['contractor'],
                            'documents': result['documents'],
                            'csv_data': project
                        }
                        result['ai_analysis'] = await analyze_with_gemini(ai_input, await self._get_session())
                    except Exception as e:
                        logger.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                        result['ai_analysis'] = f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                
                results.append(result)
                
                # Discordë¡œ ê²°ê³¼ ì „ì†¡
                try:
                    await send_audit_to_discord(result)
                except Exception as e:
                    logger.error(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
            
            return results
            
        except Exception as e:
            error_msg = f"ë‹¤ì¤‘ í”„ë¡œì íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logger.error(error_msg)
            return [{
                'error': str(e),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }]

    async def process_audit_targets(self, filters=None, use_ai=False, skip_no_folder=False):
        """ê°ì‚¬ ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ê³  ë°°ì¹˜ë¡œ ê°ì‚¬ ìˆ˜í–‰ (CSV ê¸°ë°˜)"""
        try:
            # CSV ë°ì´í„° ë¡œë“œ
            projects = await self.load_csv_data()
            
            if not projects:
                raise Exception("No projects found in CSV data")
            
            # í•„í„° ì ìš© (ìˆëŠ” ê²½ìš°)
            if filters:
                filtered_projects = []
                for project in projects:
                    match = True
                    for key, value in filters.items():
                        if key in project and str(project[key]) != str(value):
                            match = False
                            break
                    if match:
                        filtered_projects.append(project)
                projects = filtered_projects
            
            # ê²°ê³¼ ì²˜ë¦¬
            results = []
            for project in projects:
                result = self.convert_project_to_json(project)
                if use_ai:
                    try:
                        ai_input = {
                            'project_id': project['project_id'],
                            'department': result['department'],
                            'project_name': result['project_name'],
                            'status': result['status'],
                            'contractor': result['contractor'],
                            'documents': result['documents'],
                            'csv_data': project
                        }
                        result['ai_analysis'] = await analyze_with_gemini(ai_input, await self._get_session())
                    except Exception as e:
                        logger.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                        result['ai_analysis'] = f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                
                results.append(result)
                
                # Discordë¡œ ê²°ê³¼ ì „ì†¡
                try:
                    await send_audit_to_discord(result)
                except Exception as e:
                    logger.error(f"âŒ ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
            
            # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            df_results = pd.DataFrame(results)
            
            # CSV íŒŒì¼ë¡œ ì €ì¥
            output_csv = os.path.join(STATIC_DATA_PATH, 'audit_results.csv')
            df_results.to_csv(output_csv, index=False, encoding='utf-8-sig')
            
            logger.info(f"ê°ì‚¬ ê²°ê³¼ê°€ {output_csv}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ ìˆ˜: {len(df_results)}")
            return df_results, results
            
        except Exception as e:
            error_msg = f"ê°ì‚¬ ëŒ€ìƒ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
            logger.error(error_msg)
            return None, None

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="í”„ë¡œì íŠ¸ ë¬¸ì„œ ê²€ìƒ‰")
    parser.add_argument('--project-id', type=str, nargs='+', required=False, help="ê²€ìƒ‰í•  í”„ë¡œì íŠ¸ ID (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)")
    parser.add_argument('--use-ai', action='store_true', help="AI ë¶„ì„ ì‚¬ìš©")
    parser.add_argument('--skip-no-folder', action='store_true', help="No folder/No directory í”„ë¡œì íŠ¸ë¥¼ íŒ¨ìŠ¤")
    args = parser.parse_args()
    
    async def main():
    logger.info("=== í”„ë¡œì íŠ¸ ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘ ===")
    service = AuditService()
    
        try:
    if args.project_id:
                if len(args.project_id) == 1:
                    await service.audit_project(args.project_id[0], None, args.use_ai, ctx=None)
        else:
                    await service.audit_multiple_projects(args.project_id, None, args.use_ai)
    else:
                await service.process_audit_targets(use_ai=args.use_ai, skip_no_folder=args.skip_no_folder)
        finally:
            await service.close()
    logger.info("\n=== ê²€ìƒ‰ ì™„ë£Œ ===")
    
    asyncio.run(main())
    
# python audit_service.py
# python audit_service.py --project-id 20180076 --use-ai
# python audit_service.py --project-id 20240178 --use-ai
# python audit_service.py --project-id 20190088 --use-ai # ì¤€ê³µí´ë”,9999
# python audit_service.py --project-id 20190088 --use-ai # ì¤€ê³µí´ë”,9999
# python audit_service.py --project-id 20240001 --use-ai 