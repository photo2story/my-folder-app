# -*- coding: utf-8 -*-

# my_flask_app/gemini.py
import google.generativeai as genai
import os
import asyncio
import hashlib
import aiohttp
from datetime import datetime, timedelta
from typing import List, Dict
from functools import lru_cache
from config import GOOGLE_API_KEY, DISCORD_WEBHOOK_URL, DOCUMENT_TYPES
import requests
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# Gemini ì„¤ì •
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# ìºì‹œ ë° rate limit ì„¤ì •
_analysis_cache = {}
_rate_limit = asyncio.Semaphore(5)  # Gemini API ì œí•œì— ë§ì¶° ì¡°ì • (ì´ˆë‹¹ 5ê±´ ê°€ì •)
_last_request_time = {}
MIN_REQUEST_INTERVAL = 0.2  # ì´ˆë‹¹ 5ê°œ ìš”ì²­ì— ë§ì¶˜ ê°„ê²©
MAX_RETRIES = 3  # ì¬ì‹œë„ íšŸìˆ˜

class DocumentAnalyzer:
    def __init__(self):
        self._session = None
        self._cache = {}
        self._last_request_time = {}  # ì¸ìŠ¤í„´ìŠ¤ ì†ì„±ìœ¼ë¡œ ë³€ê²½
        
    async def get_session(self):
        """ë¹„ë™ê¸° HTTP ì„¸ì…˜ ê´€ë¦¬"""
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
        return self._session

    @lru_cache(maxsize=1000)
    def calculate_risk_score(self, missing_docs: tuple) -> int:
        """ë¬¸ì„œ ëˆ„ë½ì— ë”°ë¥¸ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (ì˜¤í”„ë¼ì¸)"""
        base_score = 100
        risk_weights = {
            'contract': 30,    # ê³„ì•½ì„œ
            'specification': 25,  # ê³¼ì—…ì§€ì‹œì„œ
            'budget': 20,      # ì‹¤í–‰ì˜ˆì‚°
            'completion': 15,   # ì¤€ê³µê³„
            'certificate': 10,  # ì‹¤ì ì¦ëª…
            'evaluation': 5,    # ìš©ì—­ìˆ˜í–‰í‰ê°€
            'initiation': 5,    # ì°©ìˆ˜ê³„
            'agreement': 5,     # ê³µë™ë„ê¸‰í˜‘ì •
            'deliverable1': 5,  # ì„±ê³¼í’ˆ(ë³´ê³ ì„œ)
            'deliverable2': 5   # ì„±ê³¼í’ˆ(ë„ë©´)
        }
        
        for doc in missing_docs:
            if doc in risk_weights:
                base_score -= risk_weights[doc]
        
        return max(0, base_score)

    def _generate_cache_key(self, project_data: dict) -> str:
        """ìºì‹œ í‚¤ ìƒì„± (ë¬¸ì„œ ìƒíƒœ í•´ì‹œ í¬í•¨, ë‚ ì§œ ì œê±°)"""
        docs_hash = hashlib.md5(str(project_data['documents']).encode()).hexdigest()
        return f"{project_data['project_id']}_{docs_hash}"

    async def _wait_for_rate_limit(self):
        """Rate limit ì¤€ìˆ˜ ë° ì¬ì‹œë„ ì²˜ë¦¬"""
        for attempt in range(MAX_RETRIES):
            async with _rate_limit:
                now = datetime.now()
                if self._last_request_time.get(os.getpid()):
                    elapsed = (now - self._last_request_time[os.getpid()]).total_seconds()
                    if elapsed < MIN_REQUEST_INTERVAL:
                        await asyncio.sleep(MIN_REQUEST_INTERVAL - elapsed)
                self._last_request_time[os.getpid()] = now
                return  # ì„±ê³µ ì‹œ ë°˜í™˜
            await asyncio.sleep(0.5 * (attempt + 1))  # ì¬ì‹œë„ ì „ ì§€ì—°
        raise Exception("Rate limit ì´ˆê³¼ ë˜ëŠ” ìš”ì²­ ì‹¤íŒ¨")

    async def _call_gemini_with_retry(self, prompt: str, max_retries=MAX_RETRIES) -> str:
        """Gemini API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§"""
        for attempt in range(max_retries):
            try:
                await self._wait_for_rate_limit()
                response = await asyncio.to_thread(model.generate_content, prompt)
                return response.text
            except Exception as e:
                logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(1 * (attempt + 1))  # ì¬ì‹œë„ ì „ ì§€ì—°
                else:
                    raise

    async def analyze_batch(self, projects: List[Dict]) -> List[Dict]:
        """í”„ë¡œì íŠ¸ ë°°ì¹˜ ë¶„ì„"""
        tasks = [self.analyze_with_gemini(project) for project in projects]
        return await asyncio.gather(*tasks)

    async def analyze_with_gemini(self, project_data: dict, session: aiohttp.ClientSession = None) -> str:
        """í”„ë¡œì íŠ¸ ë¬¸ì„œ ë¶„ì„ì„ ìˆ˜í–‰"""
        try:
            # ì„¸ì…˜ ê´€ë¦¬
            if session is None:
                session = await self.get_session()
                should_close = True
            else:
                should_close = False

            cache_key = self._generate_cache_key(project_data)
            if cache_key in self._cache:
                logger.debug(f"ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜: {cache_key}")
                return self._cache[cache_key]

            # ë¬¸ì„œ ìƒíƒœ ë¶„ì„
            missing_docs = []
            existing_docs = []
            for doc_type, info in project_data['documents'].items():
                doc_name = DOCUMENT_TYPES[doc_type]['name']
                if info['exists']:
                    files_count = len(info['details'])
                    existing_docs.append(f"{doc_name} ({files_count}ê°œ)")
                else:
                    missing_docs.append(doc_type)

            # ì˜¤í”„ë¼ì¸ ìœ„í—˜ë„ ê³„ì‚°
            risk_score = self.calculate_risk_score(tuple(missing_docs))

            # ìƒì„¸í™”ëœ í”„ë¡¬í”„íŠ¸
            prompt = f"""
í”„ë¡œì íŠ¸ {project_data['project_id']} ë¬¸ì„œ ë¶„ì„:
ë¶€ì„œ: {project_data['department']}

í˜„í™©:
- í™•ì¸ëœ ë¬¸ì„œ: {', '.join(existing_docs)}
- ëˆ„ë½ëœ ë¬¸ì„œ: {', '.join([DOCUMENT_TYPES[d]['name'] for d in missing_docs])}
- ê¸°ë³¸ ìœ„í—˜ë„: {risk_score}/100

ë‹¤ìŒ ì‚¬í•­ì„ ìƒì„¸íˆ í‰ê°€í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ë¬¸ì„œí™” ìƒíƒœ (ìƒ/ì¤‘/í•˜) ë° ê·¸ ì´ìœ 
2. ê°€ì¥ ì‹œê¸‰í•œ ë³´ì™„ í•„ìš” ë¬¸ì„œì™€ ì´ìœ 
3. ìœ„í—˜ë„ ì ìˆ˜ ì¡°ì • í•„ìš”ì„± (ìˆë‹¤ë©´, êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ ì œì‹œ)

ê°„ë‹¨ëª…ë£Œí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
            # Gemini API í˜¸ì¶œ
            response_text = await self._call_gemini_with_retry(prompt)
            
            analysis = f"""ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ({datetime.now().strftime('%Y-%m-%d %H:%M')}):
{response_text}

ìš”ì•½:
- í™•ì¸ëœ ë¬¸ì„œ: {len(existing_docs)}ê°œ ìœ í˜•
- ëˆ„ë½ëœ ë¬¸ì„œ: {len(missing_docs)}ê°œ ìœ í˜•
- ê¸°ë³¸ ìœ„í—˜ë„: {risk_score}/100
"""
            # ìºì‹œ ì €ì¥ (TTL 24ì‹œê°„ ì„¤ì •)
            self._cache[cache_key] = analysis
            asyncio.create_task(self._clear_cache_after_delay(cache_key, 24 * 60 * 60))  # 24ì‹œê°„ í›„ ìºì‹œ ì‚­ì œ

            # Discord ì•Œë¦¼ (ì„ íƒì , ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€)
            if DISCORD_WEBHOOK_URL:
                try:
                    notification = f"ğŸ” í”„ë¡œì íŠ¸ {project_data['project_id']} ë¶„ì„ ì™„ë£Œ (ìœ„í—˜ë„: {risk_score})"
                    async with session.post(DISCORD_WEBHOOK_URL, json={'content': notification}) as resp:
                        await resp.read()
                except Exception as e:
                    logger.error(f"Discord ì•Œë¦¼ ì‹¤íŒ¨: {str(e)}")

            logger.info(f"í”„ë¡œì íŠ¸ {project_data['project_id']} ë¶„ì„ ì™„ë£Œ, ìœ„í—˜ë„: {risk_score}/100")
            return analysis

        except Exception as e:
            error_msg = f"AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            logger.error(error_msg)
            if DISCORD_WEBHOOK_URL:
                try:
                    async with session.post(DISCORD_WEBHOOK_URL, json={'content': f"âŒ {error_msg}"}) as resp:
                        await resp.read()
                except Exception as discord_e:
                    logger.error(f"Discord ì—ëŸ¬ ì•Œë¦¼ ì‹¤íŒ¨: {str(discord_e)}")
            return error_msg

        finally:
            if should_close and session:
                await session.close()

    async def _clear_cache_after_delay(self, cache_key: str, delay_seconds: int):
        """ì§€ì •ëœ ì‹œê°„ í›„ ìºì‹œ ì‚­ì œ"""
        await asyncio.sleep(delay_seconds)
        if cache_key in self._cache:
            del self._cache[cache_key]
            logger.debug(f"ìºì‹œ ì‚­ì œ: {cache_key}")

    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self._cache.clear()
        self.calculate_risk_score.cache_clear()
        logger.info("ë¶„ì„ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self._session and not self._session.closed:
            await self._session.close()
            logger.info("HTTP ì„¸ì…˜ ì¢…ë£Œ")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
analyzer = DocumentAnalyzer()

async def analyze_with_gemini(project_data: dict, session: aiohttp.ClientSession = None) -> str:
    """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ë¥¼ ìœ„í•œ ë˜í¼"""
    return await analyzer.analyze_with_gemini(project_data, session)

def clear_analysis_cache():
    """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ë¥¼ ìœ„í•œ ë˜í¼"""
    analyzer.clear_cache()

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    async def test():
        # ì‹¤ì œ project_id="20180076" ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        test_data = {
            'project_id': '20180076',
            'department': '01010_ë„ë¡œ',  # ë˜ëŠ” '01010_ë„ë¡œ' ë“±
            'documents': {
                'contract': {'exists': True, 'details': [
                    {'name': '00 ê³„ì•½ê´€ë ¨.zip'}, {'name': '191223_ë³€ê²½ê³„ì•½ì„œ(1ì°¨).pdf'}, {'name': '200506_ë³€ê²½ê³„ì•½ì„œ(2ì°¨).pdf'}
                ]},
                'specification': {'exists': False, 'details': []},  # ê³¼ì—…ì§€ì‹œì„œ ëˆ„ë½
                'initiation': {'exists': True, 'details': [
                    {'name': 'ì°©ìˆ˜ê³„(ì˜ë½ê³µì› ì§„ì…ë„ë¡œ)_18ë…„6ì›”26ì¼ ì°©ìˆ˜.pdf'}, {'name': 'ì°©ìˆ˜ê³„.hwp'}
                ]},
                'deliverable1': {'exists': True, 'details': [
                    {'name': 'ìµœì¢… ì„±ê³¼í’ˆ ì œë³¸ í˜„í™©.hwp'}, {'name': 'ì˜ë½ê³µì›ì™¸4ì§€êµ¬ì§€ë°˜ì¡°ì‚¬ë³´ê³ ì„œ.zip'}, 
                    {'name': 'ì¸¡ëŸ‰ë³´ê³ ì„œ-ì˜ë½ê³µì› ì§„ì…ë„ë¡œê°œì„¤ê³µì‚¬ ì™¸4ê°œì†Œ ê¸°ë³¸ ë° ì‹¤ì‹œì„¤ê³„ìš©ì—­.zip'}
                ]},
                'deliverable2': {'exists': True, 'details': [
                    {'name': 'ë™êµ¬ì²­~ì¡°ëŒ€ì‚¬ê±°ë¦¬ ì„¤ê³„ë„ë©´.pdf'}
                ]},
                'completion': {'exists': True, 'details': [
                    {'name': '4.03.04 ì˜ë½ê³µì›ì™¸ 4ê°œì†Œ ì¤€ê³µê³„.zip'}, {'name': '4.03.04 ì¤€ê³µê³„.zip'}, {'name': 'ì˜ë½ê³µì› ì¤€ê³µê³„ ê³µë¬¸.pdf'}
                ]},
                'certificate': {'exists': True, 'details': [
                    {'name': 'ì‹¤ì ì¦ëª…ì„œ_ì˜ë½ê³µì›(ìµœì¢…).hwp'}, {'name': 'ì‹¤ì ì¦ëª…ì„œ_ì˜ë½ê³µì›(ìµœì¢…)_ìˆ˜ì„±.hwp'}, 
                    {'name': 'ì‹¤ì ì¦ëª…ì„œ_ì˜ë½ê³µì›(ìµœì¢…)_ìˆ˜ì„±2.hwp'}
                ]}
            }
        }
        
        try:
            result = await analyze_with_gemini(test_data)
            logger.info(result)
        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        finally:
            await analyzer.close()

    asyncio.run(test())
# python gemini.py
 